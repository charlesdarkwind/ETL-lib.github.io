<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ETL Library: ETL.dataframe_utils Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ETL Library
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespace_e_t_l.html">ETL</a></li><li class="navelem"><a class="el" href="namespace_e_t_l_1_1dataframe__utils.html">dataframe_utils</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">ETL.dataframe_utils Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:af273ce0aafcc61b9d0c119da2f2f9917"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_e_t_l_1_1dataframe__utils.html#af273ce0aafcc61b9d0c119da2f2f9917">write</a> (config, df, zone, path, num_files=None, check_df=True, **dataframe_writer_options)</td></tr>
<tr class="separator:af273ce0aafcc61b9d0c119da2f2f9917"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a538b6d98440ff39b1bade35dbd016db7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_e_t_l_1_1dataframe__utils.html#a538b6d98440ff39b1bade35dbd016db7">read</a> (config, zone, path, **dataframe_reader_options)</td></tr>
<tr class="separator:a538b6d98440ff39b1bade35dbd016db7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55775e854a18fcd1bd5c10511feb584b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_e_t_l_1_1dataframe__utils.html#a55775e854a18fcd1bd5c10511feb584b">groupby_and_to_list</a> (df, groupby_col_name, new_col_name='x')</td></tr>
<tr class="separator:a55775e854a18fcd1bd5c10511feb584b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a55775e854a18fcd1bd5c10511feb584b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55775e854a18fcd1bd5c10511feb584b">&#9670;&nbsp;</a></span>groupby_and_to_list()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def ETL.dataframe_utils.groupby_and_to_list </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>df</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groupby_col_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>new_col_name</em> = <code>'x'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Groupby column name and collect other columns as a list of structs.

Examples
________

&gt;&gt; atm_hours.show(truncate=False)
+------+-----------+---------+----------+
|ATM_ID|DAY_OF_WEEK|OPEN_HOUR|CLOSE_HOUR|
+------+-----------+---------+----------+
|1007  |1          |8:00:00  |23:00:00  |
|1007  |2          |8:00:00  |23:00:00  |
|1007  |3          |8:00:00  |23:00:00  |
+------+-----------+---------+----------+

&gt;&gt; atm_hours.printSchema()
root
 |-- ATM_ID: string
 |-- DAY_OF_WEEK: string
 |-- OPEN_HOUR: string
 |-- CLOSE_HOUR: string
 |-- DAY_OF_WEEK: string

&gt;&gt; atm_hours = groupby_and_to_list(atm_hours, 'ATM_ID', 'HOURS')

&gt;&gt; atm_hours.show(truncate=False)
+------+------------------------------------------------------------------------+
|ATM_ID|HOURS                                                                   |
+------+------------------------------------------------------------------------+
|1007  |[[1, 8:00:00, 23:00:00], [2, 8:00:00, 23:00:00], [3, 8:00:00, 23:00:00]]|
+------+------------------------------------------------------------------------+

&gt;&gt; atm_hours.printSchema()
root
 |-- ATM_ID: string
 |-- HOURS: array
 |    |-- element: struct
 |    |    |-- DAY_OF_WEEK: string
 |    |    |-- OPEN_HOUR: string
 |    |    |-- CLOSE_HOUR: string

Parameters
----------
df: pyspark.sql.DataFrame
groupby_col_name: str
new_col_name: str

Returns
-------
pyspark.sql.DataFrame
</pre> 
</div>
</div>
<a id="a538b6d98440ff39b1bade35dbd016db7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a538b6d98440ff39b1bade35dbd016db7">&#9670;&nbsp;</a></span>read()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def ETL.dataframe_utils.read </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zone</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>dataframe_reader_options</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Read all files of the folder, equivalent of doing a SELECT *

CSV, JSON, parquet or delta.

Parameters
----------
config: ETL.Config
zone: str
path: list or str
dataframe_reader_options:
  format: str

Returns
-------
pyspark.sql.DataFrame
</pre> 
</div>
</div>
<a id="af273ce0aafcc61b9d0c119da2f2f9917"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af273ce0aafcc61b9d0c119da2f2f9917">&#9670;&nbsp;</a></span>write()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def ETL.dataframe_utils.write </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>df</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>zone</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_files</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>check_df</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>dataframe_writer_options</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Writes the spark dataframe in json, csv, parquet or delta format to the specified zone.

Parameters
----------
config: ETL.Config
  Config instance
df: pyspark.sql.DataFrame
zone: str
  ADLS zone to use in path.
path: str
num_files: int, optional
  How many files to write.
check_df: bool
  Dont check if df is empty before write, large execution plans can make the dataframewriter crash
dataframe_writer_options
</pre> 
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
